
# üìö Gradiente Descendente 

Nesta atividade h√° exerc√≠cios pr√°ticos para implementa√ß√£o e an√°lise do algoritmo de **Gradiente Descendente**, ao qual se verifica a taxa de aprendizado, posi√ß√£o inicial e a presen√ßa de m√∫ltiplos m√≠nimos.


---

No exerc√≠cio 1, faz se uma an√°lise dos par√¢metros de um gradiente mais simples. Neste sentido, o exerc√≠cio busca 
visualizar a fun√ß√£o e a trajet√≥ria da part√≠cula.  Al√©m de explorar o efeito de diferentes taxas de aprendizado e posi√ß√µes iniciais.  

No exerc√≠cio 2, o processo de resolu√ß√£o foi o mesmo para uma nova fun√ß√£o.Esta fun√ß√£o tem dois m√≠nimos globais, com isso. estudou-se o comportamento do algoritmo em fun√ß√£o com m√∫ltiplos m√≠nimos globais e tamb√©m testou-se como a posi√ß√£o inicial e a taxa de aprendizado afetam o resultado.  

No exerc√≠cio 3, buscou-se investigar como a adi√ß√£o de um termo linear  altera a altura dos m√≠nimos da fun√ß√£o.
Tamb√©m foi observado a converg√™ncia do algoritmo variando a taxa de aprendizado , ùõº. Se o valor de 
muito pequeno, o algoritmo avan√ßa devagar e pode demorar muito para convergir.em contrapartida, caso seja muito grande, o algoritmo pode divergir, ou seja, os valores ficam cada vez maiores ou oscilam sem parar, o que causa erros como o overflow.

No exerc√≠cio 4, fo feito a minimiza√ß√£o da fun√ß√£o: `U(x, y) = (sin(x)cos(y) + 2(xy)¬≤) / 1000` , ao qual foi Visualizado a fun√ß√£o com gr√°fico de contorno, o desenho da trajet√≥ria da part√≠cula no plano 2D e monitorando o valor da fun√ß√£o ao longo das itera√ß√µes e explorar o impacto da taxa de aprendizado e posi√ß√£o inicial.  Este exerc√≠cio teve duas ¬¥partes:

a) Gerar gr√°fico de contorno da fun√ß√£o  com a trajet√≥ria da part√≠cula.

b) Plotar a evolu√ß√£o do valor de  ao longo das itera√ß√µes (gr√°fico  vs. , chamado de gr√°fico de epochs).